{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oDwdQkxrWfz",
        "outputId": "c309fa9b-7605-450a-985f-79916efa38eb"
      },
      "source": [
        "!pip install textacy\r\n",
        "import spacy\r\n",
        "import textacy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/99/054efc5dea92c84a850639c490541de6cba29bc148debc3c73848c5e64c2/textacy-0.10.1-py3-none-any.whl (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 5.8MB/s \n",
            "\u001b[?25hCollecting pyphen>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/5a/5bc036e01389bc6a6667a932bac3e388de6e7fa5777a6ff50e652f60ec79/Pyphen-0.10.0-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: cachetools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: pyemd>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.5.1)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.2.4)\n",
            "Requirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.41.1)\n",
            "Collecting jellyfish>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/a6/4d039bc827a102f62ce7a7910713e38fdfd7c7a40aa39c72fb14938a1473/jellyfish-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.6MB/s \n",
            "\u001b[?25hCollecting cytoolz>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/67/1c60da8ba831bfefedb64c78b9f6820bdf58972797c95644ee3191daf27a/cytoolz-0.11.0.tar.gz (477kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<0.24.0,>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.22.2.post1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (54.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (2.0.5)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.8.0->textacy) (0.11.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->textacy) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.7.4.3)\n",
            "Building wheels for collected packages: cytoolz\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.0-cp37-cp37m-linux_x86_64.whl size=1223250 sha256=a7e4b4fdc7cd38e61f13259f9170f31ffaaa527f73df9e24974d1c36bb654170\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/32/3c/9c9926b510647cacdde744b2c7acdf1ccd5896fbb7f8d5df0c\n",
            "Successfully built cytoolz\n",
            "Installing collected packages: pyphen, jellyfish, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.11.0 jellyfish-0.8.2 pyphen-0.10.0 textacy-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QVe0MlhrZRX"
      },
      "source": [
        "f = open('input1.txt', 'r')\r\n",
        "nlp = spacy.load(\"en_core_web_sm\")\r\n",
        "doc = nlp(f.read())\r\n",
        "f.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gFvXNYRrb08",
        "outputId": "b2c37624-5821-4826-9b4b-e6f9c0531f25"
      },
      "source": [
        "for token in doc:\r\n",
        "    print(token.text, token.pos_, token.dep_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DET det\n",
            "term NOUN compound\n",
            "soul NOUN nsubjpass\n",
            "is AUX auxpass\n",
            "used VERB ROOT\n",
            "in ADP prep\n",
            "the DET det\n",
            "traditional ADJ amod\n",
            "literature NOUN pobj\n",
            "as SCONJ prep\n",
            "a DET det\n",
            "synonym NOUN pobj\n",
            "for ADP prep\n",
            "one NUM nummod\n",
            "’s PART punct\n",
            "true ADJ amod\n",
            "Self NOUN pobj\n",
            "and CCONJ cc\n",
            "is AUX auxpass\n",
            "associated VERB conj\n",
            "with ADP prep\n",
            "the DET det\n",
            "\n",
            " SPACE \n",
            "subjective ADJ amod\n",
            "essence NOUN pobj\n",
            "of ADP prep\n",
            "one NUM pobj\n",
            "’s PART punct\n",
            "living NOUN acl\n",
            ". PUNCT punct\n",
            "Since SCONJ mark\n",
            ", PUNCT punct\n",
            "we PRON nsubj\n",
            "do AUX aux\n",
            "n’t PART neg\n",
            "have AUX advcl\n",
            "any DET det\n",
            "means NOUN dobj\n",
            "to PART aux\n",
            "quantify VERB relcl\n",
            "it PRON dobj\n",
            ", PUNCT punct\n",
            "the DET det\n",
            "science NOUN nsubj\n",
            "has AUX aux\n",
            "ruled VERB ROOT\n",
            "out ADP prt\n",
            "this DET det\n",
            "idea NOUN dobj\n",
            "\n",
            " SPACE \n",
            "from ADP prep\n",
            "its DET poss\n",
            "investigations NOUN pobj\n",
            ". PUNCT punct\n",
            "But CCONJ ROOT\n",
            ", PUNCT punct\n",
            "in ADP intj\n",
            "a DET det\n",
            "recent ADJ amod\n",
            "study NOUN pobj\n",
            ", PUNCT punct\n",
            "Ceylan PROPN compound\n",
            "et PROPN compound\n",
            "al PROPN appos\n",
            ". PUNCT intj\n",
            "( PUNCT punct\n",
            "2017 NUM meta\n",
            ") PUNCT punct\n",
            "has AUX aux\n",
            "reintroduced VERB ROOT\n",
            "the DET det\n",
            "word NOUN compound\n",
            "soul NOUN dobj\n",
            "to ADP aux\n",
            "scientific ADJ xcomp\n",
            "\n",
            " SPACE \n",
            "literature NOUN dobj\n",
            "and CCONJ cc\n",
            "examined VERB conj\n",
            "the DET det\n",
            "possibility NOUN dobj\n",
            "of ADP prep\n",
            "the DET det\n",
            "study NOUN pobj\n",
            "of ADP prep\n",
            "the DET det\n",
            "soul NOUN pobj\n",
            "through ADP prep\n",
            "scientific ADJ amod\n",
            "modalities NOUN pobj\n",
            ". PUNCT punct\n",
            "The DET det\n",
            "primary ADJ amod\n",
            "focus NOUN nsubj\n",
            "of ADP prep\n",
            "\n",
            " SPACE \n",
            "their DET poss\n",
            "study NOUN nsubj\n",
            "is AUX ROOT\n",
            "to PART aux\n",
            "find VERB xcomp\n",
            "and CCONJ cc\n",
            "understand VERB conj\n",
            "the DET det\n",
            "scientific ADJ amod\n",
            "analog NOUN dobj\n",
            "of ADP prep\n",
            "the DET det\n",
            "soul NOUN pobj\n",
            "as SCONJ mark\n",
            "quoted VERB advcl\n",
            "and CCONJ cc\n",
            "discussed VERB conj\n",
            "in ADP prep\n",
            "the DET det\n",
            "traditional ADJ amod\n",
            "\n",
            " SPACE \n",
            "literature NOUN pobj\n",
            ". PUNCT punct\n",
            "In ADP prep\n",
            "the DET det\n",
            "present ADJ amod\n",
            "paper NOUN pobj\n",
            ", PUNCT punct\n",
            "we PRON nsubj\n",
            "examine VERB ROOT\n",
            "the DET det\n",
            "idea NOUN dobj\n",
            "of ADP prep\n",
            "a DET det\n",
            "soul NOUN pobj\n",
            "that DET nsubj\n",
            "uses VERB relcl\n",
            "a DET det\n",
            "novel ADJ amod\n",
            "approach NOUN dobj\n",
            "; PUNCT punct\n",
            "integrating VERB advcl\n",
            "neuroscience NOUN dobj\n",
            "and CCONJ cc\n",
            "\n",
            " SPACE \n",
            "quantum PROPN compound\n",
            "physics NOUN conj\n",
            ", PUNCT punct\n",
            "as SCONJ mark\n",
            "proposed VERB advcl\n",
            "in ADP prep\n",
            "Ceylan PROPN compound\n",
            "et PROPN compound\n",
            "al PROPN pobj\n",
            ". PUNCT punct\n",
            "( PUNCT punct\n",
            "2017 NUM ROOT\n",
            ") PUNCT punct\n",
            ". PUNCT punct\n",
            "For ADP prep\n",
            "this DET det\n",
            "purpose NOUN pobj\n",
            ", PUNCT punct\n",
            "we PRON nsubj\n",
            "make VERB ROOT\n",
            "use NOUN dobj\n",
            "of ADP prep\n",
            "findings NOUN pobj\n",
            "from ADP prep\n",
            "neuroscientific PROPN pobj\n",
            "\n",
            " SPACE \n",
            "studies NOUN pobj\n",
            "on ADP prep\n",
            "meditation NOUN pobj\n",
            "to PART aux\n",
            "understand VERB advcl\n",
            "the DET det\n",
            "concepts NOUN dobj\n",
            "of ADP prep\n",
            "soul NOUN pobj\n",
            "and CCONJ cc\n",
            "consciousness NOUN conj\n",
            "in ADP prep\n",
            "terms NOUN pobj\n",
            "of ADP prep\n",
            "inhibition NOUN compound\n",
            "mechanisms NOUN pobj\n",
            ". PUNCT punct\n",
            "In ADP prep\n",
            "this DET det\n",
            "\n",
            " SPACE \n",
            "context NOUN pobj\n",
            ", PUNCT punct\n",
            "this DET det\n",
            "paper NOUN nsubj\n",
            "serves VERB ROOT\n",
            "as SCONJ prep\n",
            "an DET det\n",
            "attempt NOUN pobj\n",
            "to PART aux\n",
            "call VERB acl\n",
            "for ADP mark\n",
            "more ADJ amod\n",
            "studies NOUN nsubj\n",
            "to PART aux\n",
            "discuss VERB advcl\n",
            "and CCONJ cc\n",
            "expand VERB conj\n",
            "the DET det\n",
            "hypothesis NOUN dobj\n",
            "about ADP prep\n",
            "the DET det\n",
            "soul NOUN pobj\n",
            "\n",
            " SPACE \n",
            "as SCONJ prep\n",
            "uninhibited ADJ amod\n",
            "mental ADJ amod\n",
            "activity NOUN pobj\n",
            ". PUNCT punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8DZHKjWreUG"
      },
      "source": [
        "tuples_list = []\r\n",
        "tuples = textacy.extract.subject_verb_object_triples(doc)\r\n",
        "tuples_to_list = list(tuples)\r\n",
        "if tuples_to_list != []:\r\n",
        "    tuples_list.append(tuples_to_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaVeH75zriAR",
        "outputId": "ee141538-1c83-478a-ddf2-0b6fdf9de0a0"
      },
      "source": [
        "print(tuples_list)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(science, has ruled, idea), (we, examine, idea), (that, uses, approach), (we, make, use)]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}